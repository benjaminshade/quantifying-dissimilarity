{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains various calculations mentioned in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import pickle\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_1samp, ttest_rel\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "from scipy import stats as stats\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "## path to the downloaded gutenberg corpus\n",
    "path_gutenberg = os.path.join(os.pardir,os.pardir,'gutenberg')\n",
    "\n",
    "## import internal helper functions\n",
    "src_dir = os.path.join(os.pardir,'src')\n",
    "sys.path.append(src_dir)\n",
    "from data_io import get_book\n",
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Accessing the metadata\n",
    "sys.path.append(os.path.join(path_gutenberg,'src'))\n",
    "from metaquery import meta_query\n",
    "mq = meta_query(path=os.path.join(path_gutenberg,'metadata','metadata.csv'), filter_exist=False)\n",
    "\n",
    "from itertools import combinations\n",
    "from data_io import get_book, get_p12_same_support\n",
    "from metric_eval import prob_x_less_than_y_freq_new, prob_x_less_than_y_emb_new\n",
    "from jsd import jsdalpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying optimal values of alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_avg_se_dict(weights = False):\n",
    "    if weights:\n",
    "        string = '_weights'\n",
    "    else:\n",
    "        string = ''\n",
    "\n",
    "    dataframe_dict = {}\n",
    "    dataframe_dict_controlled = {}\n",
    "\n",
    "    task_numbers = [i for i in range(11,21)]\n",
    "    alphas = [i/20 for i in range(41)]\n",
    "    col_names = [str(i) for i in alphas]\n",
    "\n",
    "    for task in ['author', 'subject', 'time']:\n",
    "        dataframe_list = []\n",
    "        dataframe_list_controlled = []\n",
    "\n",
    "        for num in task_numbers:\n",
    "            input_file_path_opt_alpha_controlled = f'../output_files/optimal_alpha{string}_new_controlled_{task}{num}.pickle'\n",
    "            with open(input_file_path_opt_alpha_controlled, 'rb') as f:\n",
    "                opt_alpha_results_controlled = pickle.load(f)\n",
    "\n",
    "            input_file_path_opt_alpha = f'../output_files/optimal_alpha{string}_new_{task}{num}.pickle'\n",
    "            with open(input_file_path_opt_alpha, 'rb') as f:\n",
    "                opt_alpha_results = pickle.load(f)\n",
    "            \n",
    "            dataframe_list.append(opt_alpha_results.copy())\n",
    "            dataframe_list_controlled.append(opt_alpha_results_controlled.copy())\n",
    "        \n",
    "        df = pd.DataFrame(dataframe_list, columns=col_names)\n",
    "        df_controlled = pd.DataFrame(dataframe_list_controlled, columns=col_names)\n",
    "\n",
    "        alpha_avgs = []\n",
    "        alpha_stds = []\n",
    "\n",
    "        alpha_avgs_controlled = []\n",
    "        alpha_stds_controlled = []\n",
    "\n",
    "        for alpha in col_names:\n",
    "            current = df[alpha].to_numpy()\n",
    "            alpha_avgs.append(np.mean(current))\n",
    "            alpha_stds.append(np.std(current))\n",
    "\n",
    "            current_controlled = df_controlled[alpha].to_numpy()\n",
    "            alpha_avgs_controlled.append(np.mean(current_controlled))\n",
    "            alpha_stds_controlled.append(np.std(current_controlled))\n",
    "        \n",
    "        dataframe_dict[task] = (tuple(alpha_avgs), tuple(alpha_stds))\n",
    "        dataframe_dict_controlled[task] = (tuple(alpha_avgs_controlled), tuple(alpha_stds_controlled))\n",
    "    \n",
    "    return dataframe_dict_controlled, dataframe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncontrolled corpora\n",
      "author: P(X<Y) = 0.8742726, alpha = 0.65\n",
      "subject: P(X<Y) = 0.6749185, alpha = 0.6\n",
      "time: P(X<Y) = 0.5712482000000001, alpha = 0.8\n",
      "\n",
      "Controlled corpora\n",
      "author: P(X<Y) = 0.8960076000000001, alpha = 0.7\n",
      "subject: P(X<Y) = 0.6542960000000001, alpha = 0.6\n",
      "time: P(X<Y) = 0.6734418000000001, alpha = 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Uncontrolled corpora\")\n",
    "dataframe_dict_controlled, dataframe_dict = create_avg_se_dict()\n",
    "alphas = [i/20 for i in range(41)]\n",
    "task_numbers = [i for i in range(11,21)]\n",
    "for task in ['author', 'subject', 'time']:\n",
    "    vals = dataframe_dict[task][0]\n",
    "    index = vals.index(max(vals))\n",
    "    print(f'{task}: P(X<Y) = {vals[index]}, alpha = {alphas[index]}')\n",
    "\n",
    "\n",
    "print(\"\\nControlled corpora\")\n",
    "for task in ['author', 'subject', 'time']:\n",
    "    vals = dataframe_dict_controlled[task][0]\n",
    "    # index = alphas.index(1.0)\n",
    "    index = vals.index(max(vals))\n",
    "    print(f'{task}: P(X<Y) = {vals[index]}, alpha = {alphas[index]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of texts in our filtered corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13923\n"
     ]
    }
   ],
   "source": [
    "# Perform necessary filtering\n",
    "mq.reset()\n",
    "mq.filter_lang('en',how='only')\n",
    "# Only select books with more than 20 downloads\n",
    "df = mq.get_df()\n",
    "mq.df = df[df['downloads'] >= 20]\n",
    "# 1800 onwards\n",
    "mq.filter_year([1800, 2050])\n",
    "# Filter out data with no subject listed\n",
    "df = mq.get_df()\n",
    "mq.df = df[df['subjects'] != 'set()']\n",
    "# Filter out entries that don't have author birth or death year\n",
    "df = mq.get_df()\n",
    "mq.df = df[df[['authoryearofbirth', 'authoryearofdeath']].notnull().all(1)]\n",
    "\n",
    "all_uniq_ids = mq.get_ids()\n",
    "print(len(all_uniq_ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary table of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tasks</th>\n",
       "      <th>alpha=1</th>\n",
       "      <th>best alpha</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>euclidean_freq</th>\n",
       "      <th>angular</th>\n",
       "      <th>manhattan</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>euclidean_normed</th>\n",
       "      <th>jsd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>author</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>author</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>author</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>author</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>author</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>author</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>author</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>author</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>author</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          tasks  alpha=1  best alpha  jaccard  euclidean_freq  angular  \\\n",
       "0        author     0.66        0.75     0.70            0.66     0.66   \n",
       "1        author     0.90        0.92     0.86            0.89     0.86   \n",
       "2        author     0.91        0.92     0.91            0.77     0.68   \n",
       "3        author     0.92        0.94     0.89            0.91     0.85   \n",
       "4        author     0.87        0.92     0.87            0.78     0.78   \n",
       "5        author     0.86        0.90     0.85            0.81     0.82   \n",
       "6        author     0.90        0.90     0.89            0.85     0.81   \n",
       "7        author     0.98        0.98     0.94            0.97     0.92   \n",
       "8        author     0.89        0.91     0.88            0.86     0.82   \n",
       "9        author     0.93        0.94     0.89            0.88     0.81   \n",
       "10      subject     0.64        0.64     0.61            0.64     0.69   \n",
       "11      subject     0.66        0.67     0.62            0.66     0.71   \n",
       "12      subject     0.64        0.65     0.63            0.64     0.70   \n",
       "13      subject     0.65        0.66     0.65            0.65     0.71   \n",
       "14      subject     0.67        0.67     0.65            0.66     0.71   \n",
       "15      subject     0.65        0.66     0.63            0.64     0.70   \n",
       "16      subject     0.63        0.68     0.65            0.62     0.69   \n",
       "17      subject     0.64        0.68     0.65            0.63     0.69   \n",
       "18      subject     0.59        0.69     0.65            0.60     0.63   \n",
       "19      subject     0.55        0.64     0.65            0.56     0.59   \n",
       "20  time period     0.61        0.62     0.61            0.57     0.57   \n",
       "21  time period     0.62        0.65     0.62            0.55     0.51   \n",
       "22  time period     0.63        0.63     0.64            0.58     0.59   \n",
       "23  time period     0.69        0.74     0.72            0.63     0.66   \n",
       "24  time period     0.48        0.83     0.67            0.52     0.51   \n",
       "25  time period     0.65        0.67     0.67            0.57     0.57   \n",
       "26  time period     0.61        0.64     0.62            0.57     0.55   \n",
       "27  time period     0.68        0.73     0.69            0.60     0.62   \n",
       "28  time period     0.63        0.66     0.62            0.56     0.59   \n",
       "29  time period     0.54        0.68     0.53            0.49     0.53   \n",
       "\n",
       "    manhattan  euclidean  euclidean_normed   jsd  \n",
       "0        0.63       0.63              0.66  0.39  \n",
       "1        0.85       0.85              0.86  0.21  \n",
       "2        0.66       0.66              0.68  0.35  \n",
       "3        0.85       0.85              0.85  0.17  \n",
       "4        0.79       0.78              0.78  0.23  \n",
       "5        0.80       0.80              0.82  0.18  \n",
       "6        0.78       0.78              0.81  0.22  \n",
       "7        0.92       0.92              0.92  0.26  \n",
       "8        0.81       0.81              0.82  0.18  \n",
       "9        0.79       0.79              0.81  0.17  \n",
       "10       0.68       0.68              0.69  0.31  \n",
       "11       0.71       0.71              0.71  0.31  \n",
       "12       0.68       0.69              0.70  0.32  \n",
       "13       0.69       0.69              0.71  0.33  \n",
       "14       0.70       0.70              0.71  0.30  \n",
       "15       0.69       0.69              0.70  0.33  \n",
       "16       0.67       0.67              0.69  0.34  \n",
       "17       0.69       0.68              0.69  0.33  \n",
       "18       0.62       0.62              0.63  0.40  \n",
       "19       0.59       0.59              0.59  0.43  \n",
       "20       0.58       0.58              0.57  0.41  \n",
       "21       0.52       0.51              0.51  0.49  \n",
       "22       0.59       0.59              0.59  0.45  \n",
       "23       0.67       0.67              0.66  0.32  \n",
       "24       0.46       0.46              0.51  0.48  \n",
       "25       0.58       0.59              0.57  0.44  \n",
       "26       0.55       0.55              0.55  0.46  \n",
       "27       0.61       0.61              0.62  0.39  \n",
       "28       0.58       0.58              0.59  0.44  \n",
       "29       0.52       0.52              0.53  0.45  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing results\n",
    "# Columns: alpha=1, optimal alpha, jaccard, angular, manhattan, euclidean\n",
    "dataframe_dict = {'tasks' : ['author']*10 + ['subject']*10 + ['time period']*10 }\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "suffix = 'new_controlled'\n",
    "\n",
    "# Extracting the alpba=1 and optimal alpha column\n",
    "alpha1 = []\n",
    "alpha_opt = []\n",
    "# alpha1_weights = []\n",
    "# alpha_opt_weights = []\n",
    "\n",
    "for task in ['author', 'subject', 'time']:\n",
    "    task_numbers = [i for i in range(11,21)]\n",
    "\n",
    "    for num in task_numbers:\n",
    "        input_file_path_opt_alpha = f'../output_files/optimal_alpha_{suffix}_{task}{num}.pickle'\n",
    "        with open(input_file_path_opt_alpha, 'rb') as f:\n",
    "            opt_alpha_results = pickle.load(f)\n",
    "        \n",
    "        # input_file_path_opt_alpha_weights = f'../output_files/optimal_alpha_weights_{task}{num}.pickle'\n",
    "        # with open(input_file_path_opt_alpha_weights, 'rb') as f:\n",
    "        #     opt_alpha_results_weights = pickle.load(f)\n",
    "        \n",
    "        alpha1.append(round(opt_alpha_results[20],2))\n",
    "        alpha_opt.append(round(max(opt_alpha_results),2))\n",
    "        # alpha1_weights.append(round(opt_alpha_results_weights[20],2))\n",
    "        # alpha_opt.append(round(max(opt_alpha_results_weights),2))\n",
    "\n",
    "dataframe_dict['alpha=1'] = alpha1\n",
    "dataframe_dict['best alpha'] = alpha_opt\n",
    "# dataframe_dict['alpha=1 (weights)'] = alpha1_weights\n",
    "# dataframe_dict['best alpha (weights)'] = alpha_opt_weights\n",
    "\n",
    "\n",
    "# Frequency results \n",
    "for name in ['jaccard', 'euclidean_freq']:\n",
    "    input_file_path_current = f'../output_files/{name}_results_new.pickle'\n",
    "    with open(input_file_path_current, 'rb') as f:\n",
    "        results_dict = pickle.load(f)\n",
    "    all_results = []\n",
    "    current_results = results_dict[suffix]\n",
    "    for key in current_results:\n",
    "        all_results += [round(i,2) for i in current_results[key]]\n",
    "    dataframe_dict[name] = all_results\n",
    "\n",
    "\n",
    "# Extracting the columns from embeddings\n",
    "for name in ['angular', 'manhattan', 'euclidean', 'euclidean_normed', 'jsd']:\n",
    "    input_file_path_current = f'../output_files/{name}_embedding_results_new.pickle'\n",
    "    with open(input_file_path_current, 'rb') as f:\n",
    "        results_dict = pickle.load(f)\n",
    "    all_results = []\n",
    "    current_results = results_dict[suffix]\n",
    "    for key in current_results:\n",
    "        all_results += [round(i,2) for i in current_results[key]]\n",
    "    dataframe_dict[name] = all_results\n",
    "\n",
    "\n",
    "# Displaying as a dataframe\n",
    "df = pd.DataFrame(dataframe_dict)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary table of results (with average and SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tasks</th>\n",
       "      <th>alpha=1</th>\n",
       "      <th>best alpha</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>overlap</th>\n",
       "      <th>euclidean_freq</th>\n",
       "      <th>text_length</th>\n",
       "      <th>angular</th>\n",
       "      <th>manhattan</th>\n",
       "      <th>euclidean</th>\n",
       "      <th>euclidean_normed</th>\n",
       "      <th>jsd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>author</td>\n",
       "      <td>0.8288 ± 0.0035</td>\n",
       "      <td>0.8743 ± 0.0038</td>\n",
       "      <td>0.7959 ± 0.0041</td>\n",
       "      <td>0.6701 ± 0.0022</td>\n",
       "      <td>0.8133 ± 0.0025</td>\n",
       "      <td>0.6533 ± 0.0041</td>\n",
       "      <td>0.8599 ± 0.0025</td>\n",
       "      <td>0.8447 ± 0.0026</td>\n",
       "      <td>0.8448 ± 0.0026</td>\n",
       "      <td>0.8599 ± 0.0025</td>\n",
       "      <td>0.1741 ± 0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subject</td>\n",
       "      <td>0.6408 ± 0.0038</td>\n",
       "      <td>0.6749 ± 0.0048</td>\n",
       "      <td>0.6326 ± 0.0041</td>\n",
       "      <td>0.5043 ± 0.0039</td>\n",
       "      <td>0.6403 ± 0.0056</td>\n",
       "      <td>0.5956 ± 0.0042</td>\n",
       "      <td>0.6966 ± 0.004</td>\n",
       "      <td>0.6846 ± 0.0043</td>\n",
       "      <td>0.6847 ± 0.0042</td>\n",
       "      <td>0.6966 ± 0.004</td>\n",
       "      <td>0.3219 ± 0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>time period</td>\n",
       "      <td>0.5664 ± 0.003</td>\n",
       "      <td>0.5712 ± 0.0026</td>\n",
       "      <td>0.5953 ± 0.0028</td>\n",
       "      <td>0.4782 ± 0.0023</td>\n",
       "      <td>0.5295 ± 0.0033</td>\n",
       "      <td>0.5883 ± 0.0028</td>\n",
       "      <td>0.5293 ± 0.0035</td>\n",
       "      <td>0.5357 ± 0.0034</td>\n",
       "      <td>0.5354 ± 0.0034</td>\n",
       "      <td>0.5293 ± 0.0035</td>\n",
       "      <td>0.4691 ± 0.0028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tasks          alpha=1       best alpha          jaccard  \\\n",
       "0       author  0.8288 ± 0.0035  0.8743 ± 0.0038  0.7959 ± 0.0041   \n",
       "1      subject  0.6408 ± 0.0038  0.6749 ± 0.0048  0.6326 ± 0.0041   \n",
       "2  time period   0.5664 ± 0.003  0.5712 ± 0.0026  0.5953 ± 0.0028   \n",
       "\n",
       "           overlap   euclidean_freq      text_length          angular  \\\n",
       "0  0.6701 ± 0.0022  0.8133 ± 0.0025  0.6533 ± 0.0041  0.8599 ± 0.0025   \n",
       "1  0.5043 ± 0.0039  0.6403 ± 0.0056  0.5956 ± 0.0042   0.6966 ± 0.004   \n",
       "2  0.4782 ± 0.0023  0.5295 ± 0.0033  0.5883 ± 0.0028  0.5293 ± 0.0035   \n",
       "\n",
       "         manhattan        euclidean euclidean_normed              jsd  \n",
       "0  0.8447 ± 0.0026  0.8448 ± 0.0026  0.8599 ± 0.0025  0.1741 ± 0.0017  \n",
       "1  0.6846 ± 0.0043  0.6847 ± 0.0042   0.6966 ± 0.004  0.3219 ± 0.0027  \n",
       "2  0.5357 ± 0.0034  0.5354 ± 0.0034  0.5293 ± 0.0035  0.4691 ± 0.0028  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar to above, but with average values and standard errors\n",
    "# Comparing results\n",
    "# Columns: alpha=1, optimal alpha, jaccard, angular, manhattan, euclidean\n",
    "dataframe_dict = {'tasks':['author', 'subject', 'time period']}\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "suffix = 'new'\n",
    "# suffix = 'new'\n",
    "\n",
    "# Extracting the alpba=1 and optimal alpha column\n",
    "alpha1 = []\n",
    "alpha_opt = []\n",
    "# alpha1_weights = []\n",
    "# alpha_opt_weights = []\n",
    "optimal_alphas = {'author':0.65, 'subject':0.6, 'time':0.8}\n",
    "opt_alpha_indexes = {'author':13, 'subject':12, 'time':16}\n",
    "\n",
    "for task in ['author', 'subject', 'time']:\n",
    "    task_numbers = [i for i in range(11,21)]\n",
    "    opt_alpha_index = opt_alpha_indexes[task]\n",
    "\n",
    "    current_alpha1 = []\n",
    "    current_alpha_opt = []\n",
    "    # current_alpha1_weights = []\n",
    "    # current_alpha_opt_weights = []\n",
    "\n",
    "    for num in task_numbers:\n",
    "        input_file_path_opt_alpha = f'../output_files/optimal_alpha_{suffix}_{task}{num}.pickle'\n",
    "        with open(input_file_path_opt_alpha, 'rb') as f:\n",
    "            opt_alpha_results = pickle.load(f)\n",
    "        \n",
    "        # input_file_path_opt_alpha_weights = f'../output_files/optimal_alpha_weights_{task}{num}.pickle'\n",
    "        # with open(input_file_path_opt_alpha_weights, 'rb') as f:\n",
    "        #     opt_alpha_results_weights = pickle.load(f)\n",
    "\n",
    "        current_alpha1.append(opt_alpha_results[20])\n",
    "        current_alpha_opt.append(opt_alpha_results[opt_alpha_index])\n",
    "        # current_alpha1_weights.append(opt_alpha_results_weights[20])\n",
    "        # current_alpha_opt.append(max(opt_alpha_results_weights))\n",
    "    \n",
    "    alpha1.append(f'{round(np.mean(np.array(current_alpha1)), 4)}' + \n",
    "                    ' \\u00B1 ' + f'{round(np.std(np.array(current_alpha1))/np.sqrt(10), 4)}')\n",
    "    alpha_opt.append(f'{round(np.mean(np.array(current_alpha_opt)), 4)}' + \n",
    "                    ' \\u00B1 ' + f'{round(np.std(np.array(current_alpha_opt))/np.sqrt(10), 4)}')\n",
    "    # alpha1_weights.append(f'{round(np.mean(np.array(alpha1_weights)), 2)}' + ' \\u00B1 ' + f'{round(np.std(np.array(alpha1_weights)), 2)}')\n",
    "    # alpha_opt_weights = f'{round(np.mean(np.array(alpha_opt_weights)), 2)}' + ' \\u00B1 ' + f'{round(np.std(np.array(alpha_opt_weights)), 2)}'\n",
    "\n",
    "dataframe_dict['alpha=1'] = alpha1\n",
    "dataframe_dict['best alpha'] = alpha_opt\n",
    "# dataframe_dict['alpha=1 (weights)'] = alpha1_weights\n",
    "# dataframe_dict['best alpha (weights)'] = alpha_opt_weights\n",
    "\n",
    "\n",
    "\n",
    "# Frequency results \n",
    "for name in ['jaccard', 'overlap', 'euclidean_freq', 'text_length']:\n",
    "    input_file_path_current = f'../output_files/{name}_results_new.pickle'\n",
    "    with open(input_file_path_current, 'rb') as f:\n",
    "        results_dict = pickle.load(f)\n",
    "    all_results = []\n",
    "    current_results = results_dict[suffix]\n",
    "    for key in current_results:\n",
    "        all_results.append(f'{round(np.mean(np.array(current_results[key])), 4)}' + \n",
    "                            ' \\u00B1 ' + f'{round(np.std(np.array(current_results[key]))/np.sqrt(10), 4)}')\n",
    "    dataframe_dict[name] = all_results\n",
    "\n",
    "\n",
    "# Extracting the columns from embeddings\n",
    "for name in ['angular', 'manhattan', 'euclidean', 'euclidean_normed', 'jsd']:\n",
    "    input_file_path_current = f'../output_files/{name}_embedding_results_new.pickle'\n",
    "    with open(input_file_path_current, 'rb') as f:\n",
    "        results_dict = pickle.load(f)\n",
    "    all_results = []\n",
    "    current_results = results_dict[suffix]\n",
    "    for key in current_results:\n",
    "        all_results.append(f'{round(np.mean(np.array(current_results[key])), 4)}' + \n",
    "                            ' \\u00B1 ' + f'{round(np.std(np.array(current_results[key]))/np.sqrt(10), 4)}')\n",
    "    dataframe_dict[name] = all_results\n",
    "\n",
    "# Displaying as a dataframe\n",
    "df = pd.DataFrame(dataframe_dict)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.329676602796183e-11\n",
      "4.283663682397731e-09\n",
      "2.731115002236931e-10\n"
     ]
    }
   ],
   "source": [
    "# Comparing against the baseline (0.5)\n",
    "def compare_to_baseline(task, controlled, measure_name):\n",
    "    input_file_path_current = f'../output_files/{measure_name}_results_new.pickle'\n",
    "    with open(input_file_path_current, 'rb') as f:\n",
    "        results_dict = pickle.load(f)\n",
    "    all_results = []\n",
    "    current_results = results_dict[controlled][task]\n",
    "    return ttest_1samp(current_results, 0.5).pvalue\n",
    "\n",
    "for task in ['author','subject','time']:\n",
    "    for controlled in ['new']:\n",
    "        print(compare_to_baseline(task, controlled, 'text_length'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author 1.9005777297816666e-10\n",
      "subject 1.862259875507202e-05\n",
      "time 0.0162951376194747\n"
     ]
    }
   ],
   "source": [
    "# Statistical test between alpha = 1 and optimal alpha\n",
    "optimal_alphas = {'author':0.65, 'subject':0.6, 'time':0.8}\n",
    "opt_alpha_indexes = {'author':13, 'subject':12, 'time':16}\n",
    "suffix = 'new'\n",
    "\n",
    "for task in ['author', 'subject', 'time']:\n",
    "    task_numbers = [i for i in range(11,21)]\n",
    "    opt_alpha_index = opt_alpha_indexes[task]\n",
    "\n",
    "    current_alpha1 = []\n",
    "    current_alpha_opt = []\n",
    "\n",
    "    for num in task_numbers:\n",
    "        input_file_path_opt_alpha = f'../output_files/optimal_alpha_{suffix}_{task}{num}.pickle'\n",
    "        with open(input_file_path_opt_alpha, 'rb') as f:\n",
    "            opt_alpha_results = pickle.load(f)\n",
    "\n",
    "        current_alpha1.append(opt_alpha_results[20])\n",
    "        current_alpha_opt.append(opt_alpha_results[opt_alpha_index])\n",
    "    \n",
    "    print(task, ttest_rel(current_alpha1, current_alpha_opt).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 5.3739466512813736e-08\n"
     ]
    }
   ],
   "source": [
    "# Tests between optimal JSD and embedding\n",
    "optimal_alphas = {'author':0.65, 'subject':0.6, 'time':0.8}\n",
    "opt_alpha_indexes = {'author':13, 'subject':12, 'time':16}\n",
    "task = 'time'\n",
    "suffix = 'new'\n",
    "\n",
    "# Extracting JSD values\n",
    "task_numbers = [i for i in range(11,21)]\n",
    "opt_alpha_index = opt_alpha_indexes[task]\n",
    "\n",
    "current_alpha1 = []\n",
    "current_alpha_opt = []\n",
    "\n",
    "for num in task_numbers:\n",
    "    input_file_path_opt_alpha = f'../output_files/optimal_alpha_{suffix}_{task}{num}.pickle'\n",
    "    with open(input_file_path_opt_alpha, 'rb') as f:\n",
    "        opt_alpha_results = pickle.load(f)\n",
    "\n",
    "    current_alpha1.append(opt_alpha_results[20])\n",
    "    current_alpha_opt.append(opt_alpha_results[opt_alpha_index])\n",
    "\n",
    "\n",
    "# Getting embedding value\n",
    "measure_name = 'angular'\n",
    "with open(f'../output_files/{measure_name}_embedding_results_new.pickle', 'rb') as f:\n",
    "    results_dict = pickle.load(f)\n",
    "emb_results = results_dict[suffix][task]\n",
    "\n",
    "# Getting Jaccard or overlap value\n",
    "name = 'jaccard'\n",
    "input_file_path_current = f'../output_files/{name}_results_new.pickle'\n",
    "with open(input_file_path_current, 'rb') as f:\n",
    "    results_dict = pickle.load(f)\n",
    "vocab_results = results_dict[suffix][task]\n",
    "\n",
    "# result\n",
    "print(task, ttest_rel(vocab_results, current_alpha_opt).pvalue)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability of text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output subject counts in descending order\n",
    "mq.reset()\n",
    "\n",
    "# Filter by language (English only)\n",
    "mq.filter_lang('en',how='only')\n",
    "\n",
    "# Only select books with more than 20 downloads\n",
    "df = mq.get_df()\n",
    "mq.df = df[df['downloads'] >= 20]\n",
    "\n",
    "# 1800 onwards\n",
    "mq.filter_year([1800, 2050])\n",
    "\n",
    "# Filter out data with no subject listed\n",
    "df = mq.get_df()\n",
    "mq.df = df[df['subjects'] != 'set()']\n",
    "\n",
    "# Filter out data that is missing author birth and death years\n",
    "df = mq.get_df()\n",
    "mq.df = df[df[['authoryearofbirth', 'authoryearofdeath']].notnull().all(1)]\n",
    "\n",
    "all_ids = mq.get_ids()\n",
    "text_lengths = []\n",
    "\n",
    "for id in all_ids:\n",
    "    try:\n",
    "        book = get_book(id)\n",
    "    except:\n",
    "        continue\n",
    "    length = sum(book.values())\n",
    "    text_lengths.append(length)\n",
    "\n",
    "print(np.mean(np.array(text_lengths)))\n",
    "print(np.std(np.array(text_lengths)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a word frequency plot of all texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the full vocabulary\n",
    "all_ids = mq.get_ids()\n",
    "full_vocab = {}\n",
    "\n",
    "for id in all_ids:\n",
    "    try:\n",
    "        book = get_book(id)\n",
    "    except:\n",
    "        continue\n",
    "    for word in book:\n",
    "        if word in full_vocab:\n",
    "            full_vocab[word] += book[word]\n",
    "        else:\n",
    "            full_vocab[word] = book[word]\n",
    "\n",
    "# Store in a pickle file\n",
    "output_file_path = '../output_files/full_vocab.pickle'\n",
    "\n",
    "# with open(output_file_path, 'wb') as f:\n",
    "#     pickle.dump(full_vocab, f)\n",
    "\n",
    "# Rank-frequency plot of full vocabulary\n",
    "with open(output_file_path, 'rb') as f:\n",
    "        full_vocab = pickle.load(f)\n",
    "counts = []\n",
    "for word in full_vocab:\n",
    "    if full_vocab[word] > 0:\n",
    "        counts.append(full_vocab[word])\n",
    "counts.sort(reverse=True)\n",
    "freqs = np.array(counts)/sum(counts)\n",
    "ranks = [i for i in range(len(counts))]\n",
    "ranks.sort()\n",
    "\n",
    "plt.loglog(ranks, freqs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
