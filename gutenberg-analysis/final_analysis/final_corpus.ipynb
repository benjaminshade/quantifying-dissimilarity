{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## path to the downloaded gutenberg corpus\n",
    "path_gutenberg = os.path.join(os.pardir,os.pardir,'gutenberg')\n",
    "\n",
    "## import internal helper functions\n",
    "src_dir = os.path.join(os.pardir,'src')\n",
    "sys.path.append(src_dir)\n",
    "from data_io import get_book\n",
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "# Accessing the metadata\n",
    "sys.path.append(os.path.join(path_gutenberg,'src'))\n",
    "from metaquery import meta_query\n",
    "mq = meta_query(path=os.path.join(path_gutenberg,'metadata','metadata.csv'), filter_exist=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating subcorpora\n",
    "\n",
    "The names of functions and output files end in '_new' because we made a big change to how we generated the corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New author corpra\n",
    "def create_big_corpus(task, chosen_subject=None, time_period=None):\n",
    "    path_gutenberg = os.path.join(os.pardir,os.pardir,'gutenberg')\n",
    "    src_dir = os.path.join(os.pardir,'src')\n",
    "    sys.path.append(src_dir)\n",
    "    mq = meta_query(path=os.path.join(path_gutenberg,'metadata','metadata.csv'), filter_exist=False)\n",
    "\n",
    "    mq.reset()\n",
    "\n",
    "    # Perform necessary filtering\n",
    "    mq.reset()\n",
    "    mq.filter_lang('en',how='only')\n",
    "    # Only select books with more than 20 downloads\n",
    "    df = mq.get_df()\n",
    "    mq.df = df[df['downloads'] >= 20]\n",
    "    # 1800 onwards\n",
    "    mq.filter_year([1800, 2050])\n",
    "    # Filter out data with no subject listed\n",
    "    df = mq.get_df()\n",
    "    mq.df = df[df['subjects'] != 'set()']\n",
    "    # Filter out entries that don't have author birth or death year\n",
    "    df = mq.get_df()\n",
    "    mq.df = df[df[['authoryearofbirth', 'authoryearofdeath']].notnull().all(1)]\n",
    "\n",
    "    if chosen_subject is not None:\n",
    "        mq.filter_subject(chosen_subject, how='any')\n",
    "    if time_period is not None:\n",
    "        mq.filter_year(time_period)\n",
    "\n",
    "    full_df = mq.get_df()\n",
    "\n",
    "    if task == 'author':\n",
    "        id_dict = dict(full_df.groupby('author')['id'].apply(list))\n",
    "    elif task == 'subject':\n",
    "        counts = mq.get_subjects_counts()\n",
    "        filtered_subjects = [i for i in counts if counts[i] >= 20]\n",
    "        id_dict = {}\n",
    "        for subject in filtered_subjects:\n",
    "            mq.df = full_df\n",
    "            mq.filter_subject(subject, how='any')\n",
    "            ids = mq.get_ids()\n",
    "            if len(ids) > 0:\n",
    "                id_dict[subject] = ids\n",
    "    elif task == 'time':\n",
    "        time_periods = [[i,i+20] for i in range(1800, 1981, 20)]\n",
    "        id_dict = {}\n",
    "        for time_period in time_periods:\n",
    "            mq.df = full_df\n",
    "            mq.filter_year(time_period)\n",
    "            ids = mq.get_ids()\n",
    "            if len(ids) > 0:\n",
    "                id_dict[tuple(time_period)] = ids\n",
    "\n",
    "    return id_dict\n",
    "\n",
    "def create_corpus_new(task, seed, chosen_subject=None, time_period=None):\n",
    "    '''\n",
    "    Creates a new corpus, with the option to filter by subject or time period.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task : string\n",
    "        Either 'author', 'subject' or 'time'.\n",
    "    \n",
    "    seed : integer\n",
    "        Random seed used to determine which books are randomly selected.\n",
    "    \n",
    "    OPTIONAL:\n",
    "    chosen_subject : string\n",
    "        Desired subject (if wanting to filter by subject)\n",
    "    \n",
    "    time_period : list\n",
    "        Desired time period (if wanting to filter by time period).\n",
    "        Has the form [ start_year , end_year ].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "     : dictionary\n",
    "        Dictionary with the following structure:\n",
    "        { \n",
    "            'same' : [ list of book pairs ( book1, book2 ) ],\n",
    "            'different' : [ list of book pairs ( book1, book2 ) ] \n",
    "        }\n",
    "    '''\n",
    "\n",
    "    if task == 'author':\n",
    "        corpus = create_big_corpus(task, chosen_subject, time_period)\n",
    "    elif task == 'subject':\n",
    "        corpus = create_big_corpus(task, time_period=time_period)\n",
    "    elif task == 'time':\n",
    "        corpus = create_big_corpus(task, chosen_subject=chosen_subject)\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    all_keys = list(corpus.keys())\n",
    "    weighted_keys = []\n",
    "    for key in all_keys:\n",
    "        weighted_keys += [key]*len(corpus[key])\n",
    "\n",
    "    same = []\n",
    "    for _ in range(1000):\n",
    "        not_found = True\n",
    "        while not_found:\n",
    "            # group = random.sample(all_keys,1)[0]\n",
    "            group = random.sample(weighted_keys,1)[0]\n",
    "            if len(corpus[group]) < 2:\n",
    "                continue\n",
    "        \n",
    "            ids = random.sample(corpus[group],2)\n",
    "            try:\n",
    "                book1 = get_book(ids[0])\n",
    "                book2 = get_book(ids[1])\n",
    "            except:\n",
    "                continue\n",
    "            not_found = False\n",
    "\n",
    "        same.append(tuple(ids))\n",
    "    \n",
    "    different = []\n",
    "    for _ in range(1000):\n",
    "        not_found = True\n",
    "        while not_found:\n",
    "            group1, group2 = random.sample(weighted_keys,2)\n",
    "            if group1 == group2:\n",
    "                continue\n",
    "\n",
    "            # Check that time periods are at least 60 years apart\n",
    "            if task == 'time':\n",
    "                # Identify which group is earlier\n",
    "                if group1[0] > group2[0]:\n",
    "                    if group2[1] + 60 > group1[0]:\n",
    "                        continue\n",
    "                elif group1[0] < group2[0]:\n",
    "                    if group1[1] + 60 > group2[0]:\n",
    "                        continue\n",
    "                \n",
    "            id1 = random.sample(corpus[group1],1)[0]\n",
    "            id2 = random.sample(corpus[group2],1)[0]\n",
    "\n",
    "            if id1 == id2:\n",
    "                continue \n",
    "\n",
    "            # Check if books are actually in our data\n",
    "            try:\n",
    "                book1 = get_book(id1)\n",
    "                book2 = get_book(id2)\n",
    "            except:\n",
    "                continue\n",
    "            not_found = False\n",
    "\n",
    "        different.append((id1,id2))\n",
    "    \n",
    "    return {'same':same,'different':different}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating uncontrolled corpora (i.e. no filtering by author, subject or time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [48879,14413,41829,88434,4950,75725,48049,1470,93532,50150]\n",
    "author_corpora = []\n",
    "for seed in seeds:\n",
    "    author_corpora.append(create_corpus_new('author', seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [2505,99585,33607,20448,65477,13008,68250,82957,86969,52851]\n",
    "subject_corpora = []\n",
    "for seed in seeds:\n",
    "    subject_corpora.append(create_corpus_new('subject', seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [54291,6042,40198,69432,48405,63623,21104,21522,44701,94938]\n",
    "time_corpora = []\n",
    "for seed in seeds:\n",
    "    time_corpora.append(create_corpus_new('time', seed))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating controlled corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_corpora_controlled = []\n",
    "\n",
    "author_corpora_controlled.append(create_corpus_new('author', 68664, chosen_subject = 'Science fiction', time_period = [1950,2000]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 33982, chosen_subject = 'Detective and mystery stories', time_period = [1900,1950]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 55232, chosen_subject = 'Western stories', time_period = [1925,1975]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 15128, chosen_subject = 'Historical fiction', time_period = [1825,1875]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 95222, chosen_subject = 'Sea stories', time_period = [1850,1900]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 91059, chosen_subject = 'Fairy tales', time_period = [1850,1900]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 47274, chosen_subject = 'Love stories', time_period = [1875,1925]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 41424, chosen_subject = 'Adventure and adventurers -- Juvenile fiction', time_period = [1875,1925]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 81736, chosen_subject = 'Adventure stories', time_period = [1900,1950]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 54735, chosen_subject = 'England -- Fiction', time_period = [1850,1900]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_corpora_controlled = []\n",
    "\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 34042, time_period = [1800,1850]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 7102, time_period = [1825,1875]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 83270, time_period = [1850,1900]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 36586, time_period = [1850,1900]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 37779, time_period = [1875,1925]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 93047, time_period = [1875,1925]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 39314, time_period = [1900,1950]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 28939, time_period = [1900,1950]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 82848, time_period = [1925,1975]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 28169, time_period = [1950,2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_corpora_controlled = []\n",
    "\n",
    "time_corpora_controlled.append(create_corpus_new('time', 31250, chosen_subject = 'Love stories'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 57562, chosen_subject = 'Historical fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 53025, chosen_subject = 'Adventure stories'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 8031, chosen_subject = 'Psychological fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 92688, chosen_subject = 'Science fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 27926, chosen_subject = 'Fantasy fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 18753, chosen_subject = 'England -- Fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 78701, chosen_subject = 'War stories'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 56320, chosen_subject = 'Detective and mystery stories'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 97837, chosen_subject = 'Bildungsromans'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store these corpora in pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle files\n",
    "\n",
    "# Uncontrolled\n",
    "output_file_path = '../output_files/author_corpora_new.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(author_corpora, f)\n",
    "\n",
    "output_file_path = '../output_files/subject_corpora_new.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(subject_corpora, f)\n",
    "\n",
    "output_file_path = '../output_files/time_corpora_new.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(time_corpora, f)\n",
    "\n",
    "# Controlled \n",
    "output_file_path = '../output_files/author_corpora_new_controlled.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(author_corpora_controlled, f)\n",
    "\n",
    "output_file_path = '../output_files/subject_corpora_new_controlled.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(subject_corpora_controlled, f)\n",
    "\n",
    "output_file_path = '../output_files/time_corpora_new_controlled.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(time_corpora_controlled, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for adding all texts in our subcorpora to a folder to reduce memory usage on the servers\n",
    "\n",
    "This allowed us to just upload the books in our subcorpora to the servers, rather than\n",
    "all the books in the PG database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform necessary filtering\n",
    "mq.reset()\n",
    "mq.filter_lang('en',how='only')\n",
    "# Only select books with more than 20 downloads\n",
    "df = mq.get_df()\n",
    "mq.df = df[df['downloads'] >= 20]\n",
    "# 1800 onwards\n",
    "mq.filter_year([1800, 2050])\n",
    "# Filter out data with no subject listed\n",
    "df = mq.get_df()\n",
    "mq.df = df[df['subjects'] != 'set()']\n",
    "# Filter out entries that don't have author birth or death year\n",
    "df = mq.get_df()\n",
    "mq.df = df[df[['authoryearofbirth', 'authoryearofdeath']].notnull().all(1)]\n",
    "\n",
    "all_uniq_ids = mq.get_ids()\n",
    "print(len(all_uniq_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filepath = path_gutenberg + '/data/counts'\n",
    "dest_filepath = path_gutenberg + '/data/counts_final2'\n",
    "\n",
    "for filename in os.listdir(source_filepath):\n",
    "    current_filepath = source_filepath + '/' + filename\n",
    "    book_id = filename.split('_')[0]\n",
    "    if book_id in all_uniq_ids:\n",
    "        shutil.copy(current_filepath, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filepath = path_gutenberg + '/data/tokens'\n",
    "dest_filepath = path_gutenberg + '/data/tokens_final2'\n",
    "\n",
    "for filename in os.listdir(source_filepath):\n",
    "    current_filepath = source_filepath + '/' + filename\n",
    "    book_id = filename.split('_')[0]\n",
    "    if book_id in all_uniq_ids:\n",
    "        shutil.copy(current_filepath, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10083 3840 13923 13923\n"
     ]
    }
   ],
   "source": [
    "all_tokens_filepath = '../output_files/all_tokens.txt'\n",
    "f = open(all_tokens_filepath, \"r\")\n",
    "files = f.readlines()\n",
    "uploaded_ids = [file.split('_')[0] for file in files]\n",
    "remaining_ids = [id1 for id1 in all_uniq_ids if id1 not in uploaded_ids]\n",
    "print(len(uploaded_ids), len(remaining_ids), len(uploaded_ids + remaining_ids), len(all_uniq_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filepath = path_gutenberg + '/data/tokens'\n",
    "dest_filepath = path_gutenberg + '/data/tokens_remaining'\n",
    "\n",
    "for filename in os.listdir(source_filepath):\n",
    "    current_filepath = source_filepath + '/' + filename\n",
    "    book_id = filename.split('_')[0]\n",
    "    if book_id in remaining_ids:\n",
    "        shutil.copy(current_filepath, dest_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fa3f387b3ce8bd250fc96ae2335c94663faf53d23d3467a057e4a52c5129651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
