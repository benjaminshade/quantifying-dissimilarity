{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "## path to the downloaded gutenberg corpus\n",
    "path_gutenberg = os.path.join(os.pardir,os.pardir,'gutenberg')\n",
    "\n",
    "## import internal helper functions\n",
    "src_dir = os.path.join(os.pardir,'src')\n",
    "sys.path.append(src_dir)\n",
    "from data_io import get_book\n",
    "\n",
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "# Accessing the metadata\n",
    "sys.path.append(os.path.join(path_gutenberg,'src'))\n",
    "from metaquery import meta_query\n",
    "mq = meta_query(path=os.path.join(path_gutenberg,'metadata','metadata.csv'), filter_exist=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating subcorpora\n",
    "\n",
    "The names of functions and output files end in '_new' because we made a big change to how we generated the corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New author corpra\n",
    "def create_big_corpus(task, chosen_subject=None, time_period=None):\n",
    "    path_gutenberg = os.path.join(os.pardir,os.pardir,'gutenberg')\n",
    "    src_dir = os.path.join(os.pardir,'src')\n",
    "    sys.path.append(src_dir)\n",
    "    mq = meta_query(path=os.path.join(path_gutenberg,'metadata','metadata.csv'), filter_exist=False)\n",
    "\n",
    "    mq.reset()\n",
    "\n",
    "    # Perform necessary filtering\n",
    "    mq.reset()\n",
    "    mq.filter_lang('en',how='only')\n",
    "    # Only select books with more than 20 downloads\n",
    "    df = mq.get_df()\n",
    "    mq.df = df[df['downloads'] >= 20]\n",
    "    # 1800 onwards\n",
    "    mq.filter_year([1800, 2050])\n",
    "    # Filter out data with no subject listed\n",
    "    df = mq.get_df()\n",
    "    mq.df = df[df['subjects'] != 'set()']\n",
    "    # Filter out entries that don't have author birth or death year\n",
    "    df = mq.get_df()\n",
    "    mq.df = df[df[['authoryearofbirth', 'authoryearofdeath']].notnull().all(1)]\n",
    "\n",
    "    if chosen_subject is not None:\n",
    "        mq.filter_subject(chosen_subject, how='any')\n",
    "    if time_period is not None:\n",
    "        mq.filter_year(time_period)\n",
    "\n",
    "    full_df = mq.get_df()\n",
    "\n",
    "    if task == 'author':\n",
    "        id_dict = dict(full_df.groupby('author')['id'].apply(list))\n",
    "    elif task == 'subject':\n",
    "        counts = mq.get_subjects_counts()\n",
    "        filtered_subjects = [i for i in counts if counts[i] >= 20]\n",
    "        id_dict = {}\n",
    "        for subject in filtered_subjects:\n",
    "            mq.df = full_df\n",
    "            mq.filter_subject(subject, how='any')\n",
    "            ids = mq.get_ids()\n",
    "            if len(ids) > 0:\n",
    "                id_dict[subject] = ids\n",
    "    elif task == 'time':\n",
    "        time_periods = [[i,i+20] for i in range(1800, 1981, 20)]\n",
    "        id_dict = {}\n",
    "        for time_period in time_periods:\n",
    "            mq.df = full_df\n",
    "            mq.filter_year(time_period)\n",
    "            ids = mq.get_ids()\n",
    "            if len(ids) > 0:\n",
    "                id_dict[tuple(time_period)] = ids\n",
    "\n",
    "    return id_dict\n",
    "\n",
    "def create_corpus_new(task, seed, chosen_subject=None, time_period=None):\n",
    "    if task == 'author':\n",
    "        corpus = create_big_corpus(task, chosen_subject, time_period)\n",
    "    elif task == 'subject':\n",
    "        corpus = create_big_corpus(task, time_period=time_period)\n",
    "    elif task == 'time':\n",
    "        corpus = create_big_corpus(task, chosen_subject=chosen_subject)\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    all_keys = list(corpus.keys())\n",
    "    weighted_keys = []\n",
    "    for key in all_keys:\n",
    "        weighted_keys += [key]*len(corpus[key])\n",
    "\n",
    "    same = []\n",
    "    for _ in range(1000):\n",
    "        not_found = True\n",
    "        while not_found:\n",
    "            # group = random.sample(all_keys,1)[0]\n",
    "            group = random.sample(weighted_keys,1)[0]\n",
    "            if len(corpus[group]) < 2:\n",
    "                continue\n",
    "        \n",
    "            ids = random.sample(corpus[group],2)\n",
    "            try:\n",
    "                book1 = get_book(ids[0])\n",
    "                book2 = get_book(ids[1])\n",
    "            except:\n",
    "                continue\n",
    "            not_found = False\n",
    "\n",
    "        same.append(tuple(ids))\n",
    "    \n",
    "    different = []\n",
    "    for _ in range(1000):\n",
    "        not_found = True\n",
    "        while not_found:\n",
    "            group1, group2 = random.sample(weighted_keys,2)\n",
    "            if group1 == group2:\n",
    "                continue\n",
    "\n",
    "            # Check that time periods are at least 60 years apart\n",
    "            if task == 'time':\n",
    "                # Identify which group is earlier\n",
    "                if group1[0] > group2[0]:\n",
    "                    if group2[1] + 60 > group1[0]:\n",
    "                        continue\n",
    "                elif group1[0] < group2[0]:\n",
    "                    if group1[1] + 60 > group2[0]:\n",
    "                        continue\n",
    "                \n",
    "            id1 = random.sample(corpus[group1],1)[0]\n",
    "            id2 = random.sample(corpus[group2],1)[0]\n",
    "\n",
    "            if id1 == id2:\n",
    "                continue \n",
    "\n",
    "            try:\n",
    "                book1 = get_book(id1)\n",
    "                book2 = get_book(id2)\n",
    "            except:\n",
    "                continue\n",
    "            not_found = False\n",
    "\n",
    "        different.append((id1,id2))\n",
    "    \n",
    "    return {'same':same,'different':different}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating uncontrolled corpora (i.e. no filtering by author, subject or time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [48879,14413,41829,88434,4950,75725,48049,1470,93532,50150]\n",
    "author_corpora = []\n",
    "for seed in seeds:\n",
    "    author_corpora.append(create_corpus_new('author', seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [2505,99585,33607,20448,65477,13008,68250,82957,86969,52851]\n",
    "subject_corpora = []\n",
    "for seed in seeds:\n",
    "    subject_corpora.append(create_corpus_new('subject', seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [54291,6042,40198,69432,48405,63623,21104,21522,44701,94938]\n",
    "time_corpora = []\n",
    "for seed in seeds:\n",
    "    time_corpora.append(create_corpus_new('time', seed))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating controlled corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_corpora_controlled = []\n",
    "\n",
    "author_corpora_controlled.append(create_corpus_new('author', 68664, chosen_subject = 'Science fiction', time_period = [1950,2000]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 33982, chosen_subject = 'Detective and mystery stories', time_period = [1900,1950]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 55232, chosen_subject = 'Western stories', time_period = [1925,1975]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 15128, chosen_subject = 'Historical fiction', time_period = [1825,1875]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 95222, chosen_subject = 'Sea stories', time_period = [1850,1900]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 91059, chosen_subject = 'Fairy tales', time_period = [1850,1900]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 47274, chosen_subject = 'Love stories', time_period = [1875,1925]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 41424, chosen_subject = 'Adventure and adventurers -- Juvenile fiction', time_period = [1875,1925]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 81736, chosen_subject = 'Adventure stories', time_period = [1900,1950]))\n",
    "author_corpora_controlled.append(create_corpus_new('author', 54735, chosen_subject = 'England -- Fiction', time_period = [1850,1900]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_corpora_controlled = []\n",
    "\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 34042, time_period = [1800,1850]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 7102, time_period = [1825,1875]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 83270, time_period = [1850,1900]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 36586, time_period = [1850,1900]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 37779, time_period = [1875,1925]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 93047, time_period = [1875,1925]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 39314, time_period = [1900,1950]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 28939, time_period = [1900,1950]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 82848, time_period = [1925,1975]))\n",
    "subject_corpora_controlled.append(create_corpus_new('subject', 28169, time_period = [1950,2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_corpora_controlled = []\n",
    "\n",
    "time_corpora_controlled.append(create_corpus_new('time', 31250, chosen_subject = 'Love stories'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 57562, chosen_subject = 'Historical fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 53025, chosen_subject = 'Adventure stories'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 8031, chosen_subject = 'Psychological fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 92688, chosen_subject = 'Science fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 27926, chosen_subject = 'Fantasy fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 18753, chosen_subject = 'England -- Fiction'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 78701, chosen_subject = 'War stories'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 56320, chosen_subject = 'Detective and mystery stories'))\n",
    "time_corpora_controlled.append(create_corpus_new('time', 97837, chosen_subject = 'Bildungsromans'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle files\n",
    "\n",
    "# Uncontrolled\n",
    "output_file_path = '../output_files/author_corpora_new.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(author_corpora, f)\n",
    "\n",
    "output_file_path = '../output_files/subject_corpora_new.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(subject_corpora, f)\n",
    "\n",
    "output_file_path = '../output_files/time_corpora_new.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(time_corpora, f)\n",
    "\n",
    "# Controlled \n",
    "output_file_path = '../output_files/author_corpora_new_controlled.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(author_corpora_controlled, f)\n",
    "\n",
    "output_file_path = '../output_files/subject_corpora_new_controlled.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(subject_corpora_controlled, f)\n",
    "\n",
    "output_file_path = '../output_files/time_corpora_new_controlled.pickle'\n",
    "with open(output_file_path, 'wb') as f:\n",
    "    pickle.dump(time_corpora_controlled, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for adding all texts in our subcorpuses to a folder to reduce memory usage on the servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform necessary filtering\n",
    "mq.reset()\n",
    "mq.filter_lang('en',how='only')\n",
    "# Only select books with more than 20 downloads\n",
    "df = mq.get_df()\n",
    "mq.df = df[df['downloads'] >= 20]\n",
    "# 1800 onwards\n",
    "mq.filter_year([1800, 2050])\n",
    "# Filter out data with no subject listed\n",
    "df = mq.get_df()\n",
    "mq.df = df[df['subjects'] != 'set()']\n",
    "# Filter out entries that don't have author birth or death year\n",
    "df = mq.get_df()\n",
    "mq.df = df[df[['authoryearofbirth', 'authoryearofdeath']].notnull().all(1)]\n",
    "\n",
    "all_uniq_ids = mq.get_ids()\n",
    "print(len(all_uniq_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filepath = path_gutenberg + '/data/counts'\n",
    "dest_filepath = path_gutenberg + '/data/counts_final2'\n",
    "\n",
    "for filename in os.listdir(source_filepath):\n",
    "    current_filepath = source_filepath + '/' + filename\n",
    "    book_id = filename.split('_')[0]\n",
    "    if book_id in all_uniq_ids:\n",
    "        shutil.copy(current_filepath, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filepath = path_gutenberg + '/data/tokens'\n",
    "dest_filepath = path_gutenberg + '/data/tokens_final2'\n",
    "\n",
    "for filename in os.listdir(source_filepath):\n",
    "    current_filepath = source_filepath + '/' + filename\n",
    "    book_id = filename.split('_')[0]\n",
    "    if book_id in all_uniq_ids:\n",
    "        shutil.copy(current_filepath, dest_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10083 3840 13923 13923\n"
     ]
    }
   ],
   "source": [
    "all_tokens_filepath = '../output_files/all_tokens.txt'\n",
    "f = open(all_tokens_filepath, \"r\")\n",
    "files = f.readlines()\n",
    "uploaded_ids = [file.split('_')[0] for file in files]\n",
    "remaining_ids = [id1 for id1 in all_uniq_ids if id1 not in uploaded_ids]\n",
    "print(len(uploaded_ids), len(remaining_ids), len(uploaded_ids + remaining_ids), len(all_uniq_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_filepath = path_gutenberg + '/data/tokens'\n",
    "dest_filepath = path_gutenberg + '/data/tokens_remaining'\n",
    "\n",
    "for filename in os.listdir(source_filepath):\n",
    "    current_filepath = source_filepath + '/' + filename\n",
    "    book_id = filename.split('_')[0]\n",
    "    if book_id in remaining_ids:\n",
    "        shutil.copy(current_filepath, dest_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fa3f387b3ce8bd250fc96ae2335c94663faf53d23d3467a057e4a52c5129651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
